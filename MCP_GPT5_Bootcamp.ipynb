{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d00130",
   "metadata": {},
   "source": [
    "# MCP + GPT‑5 Hands‑On\n",
    "\n",
    "This notebook walks you through the **Model Context Protocol (MCP)** and **OpenAI GPT‑5** with a practical, step‑by‑step approach.\n",
    "You'll:\n",
    "- Understand the MCP client/server pattern\n",
    "- Build a tiny MCP server (Python) and call a tool\n",
    "- Connect an LLM workflow that calls **GPT‑5** via the **OpenAI Python SDK** (Responses API)\n",
    "- Try structured outputs, function/tool calling, and safety tips\n",
    "\n",
    "> References (keep handy):\n",
    "- MCP overview & spec: modelcontextprotocol.io\n",
    "- OpenAI API docs (GPT‑5, Responses API, Python SDK)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e57826",
   "metadata": {},
   "source": [
    "## 📦 Prerequisites\n",
    "**You need:**\n",
    "- Python 3.10+\n",
    "- An OpenAI API key with access to GPT‑5 (`OPENAI_API_KEY`)\n",
    "- (Optional) NodeJS if you want to explore MCP in Node later\n",
    "\n",
    "**Create a virtual environment (optional):**\n",
    "```bash\n",
    "python -m venv .venv && source .venv/bin/activate  # Windows: .venv\\Scripts\\activate\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6d3dc",
   "metadata": {},
   "source": [
    "## 🔧 Install Dependencies\n",
    "We’ll use:\n",
    "- `openai` — Official OpenAI Python SDK (v1+)\n",
    "- `mcp` tooling — fast server helper from MCP Python SDK (`mcp`/`mcp[fast]` depending on packaging)\n",
    "- `pydantic` — for structured outputs (optional but handy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running locally, uncomment to install\n",
    "# %pip install --upgrade openai pydantic\n",
    "# %pip install --upgrade \"mcp\" \"mcp[fast]\"  # or: %pip install modelcontextprotocol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76963918",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade openai pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade \"mcp\" \"mcp[fast]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9553eae1",
   "metadata": {},
   "source": [
    "## 🔐 Configure Environment\n",
    "Set your API key securely. In a shell:\n",
    "```bash\n",
    "export OPENAI_API_KEY='sk-...'\n",
    "```\n",
    "Or within this notebook **for demo only** (avoid committing keys):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf231970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['OPENAI_API_KEY'] = 'sk-...'  # ⚠️ Demo only. Prefer environment variables.\n",
    "assert 'OPENAI_API_KEY' in os.environ or True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de4000",
   "metadata": {},
   "source": [
    "## 🌐 Quick Intro: What is MCP?\n",
    "MCP is a **client–server** protocol that standardizes how LLM apps connect to **tools, data sources, and workflows**. Think of it as a **USB‑C for AI apps** — build a server once and any MCP‑compatible client can use it.\n",
    "\n",
    "**Core pieces:**\n",
    "- **MCP Server**: wraps tools/data (e.g., a calculator, database, Jira, filesystem)\n",
    "- **MCP Client/Host**: your app or IDE that talks to LLMs & routes tool calls\n",
    "- **Transport**: stdio, HTTP, WebSockets, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543c763",
   "metadata": {},
   "source": [
    "## 🧪 Lab 1 — Build a Tiny MCP Server (Python)\n",
    "We'll expose one simple tool `add(a, b)` and one dataset `motd` using the fast MCP helper.\n",
    "\n",
    "**Folder structure (suggested):**\n",
    "```\n",
    "mcp_demo/\n",
    "  server.py\n",
    "  client.py (optional)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d89ce72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_server.py\n",
    "\n",
    "# mcp_server.py\n",
    "import asyncio\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"DemoServer\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def message_of_the_day() -> str:\n",
    "    \"\"\"Return a motivational message.\"\"\"\n",
    "    return \"Stay curious. Build boldly.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run using stdio transport\n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mcp_server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5b48e",
   "metadata": {},
   "source": [
    "## 🧪 Lab 2 — Minimal MCP Client (Python)\n",
    "\n",
    "Let's connect to our server and call the `add` tool. Different client helpers exist; here we illustrate a minimal stdio client to send a JSON‑RPC style request.\n",
    "\n",
    "For production, prefer the official MCP client helpers when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b283312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_client.py\n",
    "\n",
    "import asyncio\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "async def main():\n",
    "    params = StdioServerParameters(command=\"python\", args=[\"mcp_server.py\"])\n",
    "\n",
    "    async with stdio_client(params) as (read_stream, write_stream):\n",
    "        async with ClientSession(read_stream, write_stream) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            tools = await session.list_tools()\n",
    "            # Each entry is (name, schema_dict)\n",
    "            tool_names = [t[0] for t in tools]\n",
    "            print(\"Available tools:\", tool_names)\n",
    "\n",
    "            # Call a tool\n",
    "            motd = await session.call_tool(\"message_of_the_day\", {})\n",
    "            print(\"message_of_the_day() =\", motd.structuredContent.get(\"result\"))\n",
    "\n",
    "            result = await session.call_tool(\"add\", {\"a\": 10, \"b\": 5})\n",
    "            print(\"add(10,5) =\", result.structuredContent.get(\"result\"))\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e526eaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2;36m[10/31/25 22:36:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing request of type            \u001b]8;id=442060;file:///opt/anaconda3/lib/python3.11/site-packages/mcp/server/lowlevel/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=135039;file:///opt/anaconda3/lib/python3.11/site-packages/mcp/server/lowlevel/server.py#674\u001b\\\u001b[2m674\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         ListToolsRequest                      \u001b[2m             \u001b[0m\n",
      "Available tools: ['meta', 'nextCursor', 'tools']\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing request of type            \u001b]8;id=250958;file:///opt/anaconda3/lib/python3.11/site-packages/mcp/server/lowlevel/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=436207;file:///opt/anaconda3/lib/python3.11/site-packages/mcp/server/lowlevel/server.py#674\u001b\\\u001b[2m674\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         CallToolRequest                       \u001b[2m             \u001b[0m\n",
      "message_of_the_day() = Stay curious. Build boldly.\n",
      "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing request of type            \u001b]8;id=157347;file:///opt/anaconda3/lib/python3.11/site-packages/mcp/server/lowlevel/server.py\u001b\\\u001b[2mserver.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=660450;file:///opt/anaconda3/lib/python3.11/site-packages/mcp/server/lowlevel/server.py#674\u001b\\\u001b[2m674\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m                    \u001b[0m         CallToolRequest                       \u001b[2m             \u001b[0m\n",
      "add(10,5) = 15\n"
     ]
    }
   ],
   "source": [
    "!python mcp_client.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf987be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f0514",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "\n",
    "Real clients manage sessions, schemas, discovery, and streaming.\n",
    "See the MCP docs for full client helpers and message formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25257b20",
   "metadata": {},
   "source": [
    "## 🤖 GPT‑5 with OpenAI Python SDK (Responses API)\n",
    "We will use the **Responses API** for a unified interface (chat + tools + multimodal). Make sure your `openai` package is v1+.\n",
    "\n",
    "**Basic text generation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79be9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model Context Protocol (MCP) is an open standard that lets AI assistants securely interact with your bank’s existing systems—databases, CRMs, payment rails—through governed connectors that expose only approved data and actions. Instead of copying data into the model, the assistant requests operations via MCP while your infrastructure enforces authentication, least-privilege access, redaction, and full audit logging, keeping sensitive information inside your environment. This enables use cases like KYC summaries, risk reports, or workflow initiation with human approval where needed. MCP standardizes tool access, reduces integration effort, and supports regulatory and data residency requirements.\n"
     ]
    }
   ],
   "source": [
    "# Basic GPT‑5 text generation using the Responses API\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5\" ,  # or the exact variant you have access to, e.g., \"gpt-5-large\"\n",
    "    input=\"Explain the Model Context Protocol in one short paragraph for a banking audience.\"\n",
    ")\n",
    "print(resp.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4db253",
   "metadata": {},
   "source": [
    "### 🧱 Structured Outputs (JSON)\n",
    "Ask GPT‑5 to return **well‑typed JSON** you can parse programmatically. Use instructions + `response_format=\"json_object\"` or tool schemas when available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9f7209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Market Clearing Price (MCP) in Financial and Energy Markets',\n",
       " 'summary': 'The Market Clearing Price (MCP) is the price at which aggregate supply equals aggregate demand, clearing the market without surplus or shortage. In financial exchanges and auctions, MCP is determined by matching buy and sell orders—often via call auctions or continuous order books—and sets the uniform transaction price for all matched volume at the clearing event. In power and energy markets, MCP typically refers to the uniform price in day-ahead or intraday auctions, distinct from locational marginal prices that incorporate transmission constraints. MCP underpins price discovery, allocation efficiency, and settlement, and is central to strategy design for bidders and market makers. Practitioners monitor MCP dynamics to manage execution risk, slippage, and volatility, and hedge exposure using futures, options, or bilateral contracts. Key considerations include auction design, tick size, market depth, and the potential for strategic bidding or manipulation around clearing times.',\n",
       " 'tags': ['market-clearing-price',\n",
       "  'auctions',\n",
       "  'order-books',\n",
       "  'price-discovery',\n",
       "  'market-microstructure',\n",
       "  'uniform-price-auction',\n",
       "  'energy-markets',\n",
       "  'electricity-trading',\n",
       "  'risk-management',\n",
       "  'hedging']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from json import loads\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=(\n",
    "        \"Return a JSON object with keys: 'title' (string), 'summary' (string), \"\n",
    "        \"and 'tags' (array of strings) about MCP in finance.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "data = loads(resp.output_text)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44fa5f3",
   "metadata": {},
   "source": [
    "### 🛠️ Tool (Function) Calling Pattern\n",
    "Let the model decide when to call your function to fetch external data. In Responses API, register **tools** with JSON schema and handle **tool calls**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12603546",
   "metadata": {},
   "source": [
    "## 🛡️ Security & Safety Checklist\n",
    "- **Prompt‑injection**: sanitize all model‑provided tool arguments; whitelist operations\n",
    "- **AuthZ**: scope your MCP servers; avoid broad filesystem access in prod\n",
    "- **Rate limits**: add caching and backoff around API calls\n",
    "- **Privacy**: log minimally; scrub PII; encrypt at rest & in transit\n",
    "- **Observability**: capture traces/metrics (latency, tool use, costs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd0773e",
   "metadata": {},
   "source": [
    "## 🧰 Troubleshooting\n",
    "- `ModuleNotFoundError`: verify your venv and `pip show openai mcp`\n",
    "- Tool call schema mismatches: ensure parameter names/types match your MCP tool\n",
    "- Empty `output_text`: check rate limits or ensure your model name is correct and you have access\n",
    "- For MCP transport issues: try `stdio` locally before websockets/HTTP\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
